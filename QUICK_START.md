## ğŸš€ Quick Start Guide - Enhanced Tableau Data Assistant

### Installation (5 minutes)

```bash
# Navigate to project
cd /Users/nrjs/Desktop/Tableau_Project

# Activate virtual environment
source venv/bin/activate

# Install all dependencies
pip install -r requirements.txt

# Verify installation
python -c "from utils import get_logger; print('âœ… Installation successful!')"
```

### Run the Application

```bash
# Start the Streamlit app
streamlit run scripts/tableau_chatbot.py
```

### Quick Feature Demo

#### 1. Use Enhanced Logging

```python
from utils import get_logger

logger = get_logger(__name__)
logger.info("Application started")
logger.error("Something went wrong")

# Check logs
tail -f logs/app.log
```

#### 2. Cache Expensive Operations

```python
from utils import cached

@cached(ttl=3600, key_prefix="analysis")
def expensive_analysis(dataframe):
    # This will be cached for 1 hour
    return perform_complex_analysis(dataframe)
```

#### 3. Calculate Data Quality

```python
from utils import calculate_quality_score

quality = calculate_quality_score(df)
print(f"Quality Score: {quality['overall_score']}/100")
print(f"Grade: {quality['grade']}")
```

#### 4. Create Interactive Visualizations

```python
from utils.visualizations import create_visualizations

vizualizations = create_visualizations(df, quality_score)

# In Streamlit:
st.plotly_chart(visualizations['quality_gauge'])
st.plotly_chart(visualizations['correlations'])
```

#### 5. Generate Reports

```python
from utils import get_report_generator

report_gen = get_report_generator()

# PDF Report
pdf_path = report_gen.generate_pdf_report(
    filename="my_analysis",
    title="Data Analysis Report",
    data_summary=info,
    quality_score=quality_score
)

# HTML Report
html_path = report_gen.generate_html_report(
    filename="my_analysis",
    title="Data Analysis Report",
    data_summary=info,
    quality_score=quality_score
)
```

#### 6. Save/Load Sessions

```python
from utils import get_session_manager

session_mgr = get_session_manager()

# Save current session
session_id = session_mgr.save_session(
    messages=messages,
    files_info=files,
    session_name="My Analysis"
)

# Load session later
session_data = session_mgr.load_session(session_id)
messages = session_data['messages']
```

#### 7. Security Validation

```python
from utils import get_security_manager

security = get_security_manager()

# Validate uploaded file
is_valid, error = security.validate_file(file_path, file_content)
if not is_valid:
    print(f"Security error: {error}")

# Encrypt API key
encrypted = security.encrypt_api_key("sk-ant-...")
decrypted = security.decrypt_api_key(encrypted)
```

#### 8. Statistical Analysis

```python
from utils import perform_statistical_analysis

stats = perform_statistical_analysis(df)

# Check normality
print(stats['normality_tests'])

# Find correlations
print(stats['correlations'])

# Detect outliers
print(stats['outliers'])
```

### Configuration

Edit `config/settings.py` to customize:

```python
# File limits
MAX_FILE_SIZE_MB = 500

# Quality weights
QUALITY_WEIGHTS = {
    "completeness": 0.30,
    "uniqueness": 0.20,
    "validity": 0.25,
    "consistency": 0.15,
    "timeliness": 0.10
}

# Cache settings
CACHE_TTL = 3600  # 1 hour
```

### Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test
pytest tests/test_data_quality.py -v

# With coverage
pytest tests/ --cov=utils --cov-report=html
```

### Troubleshooting

**Module not found?**
```bash
export PYTHONPATH="${PYTHONPATH}:/Users/nrjs/Desktop/Tableau_Project"
```

**python-magic errors?**
```bash
# macOS
brew install libmagic

# Linux
sudo apt-get install libmagic1
```

**Permission errors on cache/logs?**
```bash
chmod -R 755 cache/ logs/ sessions/ exports/
```

### Project Structure

```
Tableau_Project/
â”œâ”€â”€ config/                 # Configuration settings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ utils/                  # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py          # Logging system
â”‚   â”œâ”€â”€ cache_manager.py   # Caching
â”‚   â”œâ”€â”€ security.py        # Security
â”‚   â”œâ”€â”€ data_quality.py    # Quality scoring
â”‚   â”œâ”€â”€ statistics.py      # Statistical analysis
â”‚   â”œâ”€â”€ session_manager.py # Session persistence
â”‚   â”œâ”€â”€ report_generator.py # Reports
â”‚   â””â”€â”€ visualizations.py  # Plotly charts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ tableau_chatbot.py # Main application
â”‚   â””â”€â”€ tableau_chatbot_backup.py
â”œâ”€â”€ tests/                 # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_data_quality.py
â”œâ”€â”€ cache/                 # Cached analyses
â”œâ”€â”€ sessions/              # Saved sessions
â”œâ”€â”€ exports/               # Generated reports
â”œâ”€â”€ logs/                  # Application logs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md
â””â”€â”€ QUICK_START.md
```

### Key Features Ready to Use

âœ… **Logging**: Automatic file and console logging
âœ… **Caching**: Speeds up repeated analyses
âœ… **Security**: File validation and API key encryption
âœ… **Quality Scoring**: 5-dimension data quality assessment
âœ… **Statistics**: Normality tests, correlations, t-tests, chi-square
âœ… **Sessions**: Save and restore your work
âœ… **Reports**: Beautiful PDF and HTML exports
âœ… **Visualizations**: Interactive Plotly dashboards

### Example Workflow

```python
# 1. Load and validate data
df = pd.read_csv("data.csv")

# 2. Calculate quality score
quality = calculate_quality_score(df)

# 3. Run statistical analysis
stats = perform_statistical_analysis(df)

# 4. Create visualizations
viz = create_visualizations(df, quality)

# 5. Generate report
report_gen.generate_pdf_report(
    filename="analysis_report",
    title="Data Analysis",
    data_summary={'rows': len(df), 'columns': len(df.columns)},
    quality_score=quality,
    statistical_analysis=stats
)

# 6. Save session
session_mgr.save_session(
    messages=messages,
    files_info=[{'name': 'data.csv', 'info': quality}],
    session_name="My Analysis Session"
)
```

### Next Steps

1. âœ… Install dependencies
2. âœ… Run tests to verify everything works
3. ğŸ“ Integrate features into main app (see IMPLEMENTATION_GUIDE.md)
4. ğŸ¨ Customize settings in config/settings.py
5. ğŸš€ Start analyzing data!

### Support

- Check logs: `tail -f logs/app.log`
- Clear cache: `rm -rf cache/*`
- Reset sessions: `rm -rf sessions/*`
- View documentation: `IMPLEMENTATION_GUIDE.md`

Happy analyzing! ğŸ‰
